{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Must do\n",
    "\n",
    "1. exclude those who have a date lost to follow-up below May 2017 based on data-field 191 (done in extract features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'save_obj' from 'UKBB' (/home/mo/Env_vars_DL/UKBB.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-72-adfbe40be5c9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mdatetime\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdatetime\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mUKBB\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mUKBDicts\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpreprocess\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtidy_coded_fieldID\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msave_obj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'save_obj' from 'UKBB' (/home/mo/Env_vars_DL/UKBB.py)"
     ]
    }
   ],
   "source": [
    "from IPython.display import display, HTML\n",
    "import pandas as pd\n",
    "from lxml import etree\n",
    "import time\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import codecs\n",
    "#import dask.dataframe as dd\n",
    "#import dask.array as da\n",
    "import numpy as np\n",
    "import pickle\n",
    "from datetime import datetime\n",
    "from UKBB import UKBDicts,preprocess,tidy_coded_fieldID,save_obj\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import unicodedata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#PATH_data=r\"/home/workspace/datasets/ukbiobank/ukbiobank_yajiez/dataset/ukb26438.csv\"\n",
    "#PATH_dict=r\"/home/workspace/datasets/ukbiobank/ukbiobank_yajiez/dataset/ukb26438.html\"\n",
    "\n",
    "PATH_data=r\"/home/workspace/datasets/ukbiobank/biobank_milad_34943/ukb34943.csv\"\n",
    "PATH_dict=r\"/home/mo/ukb34943.html\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Read data as pd for correctness check"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 read datafields by categories in numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded a dictionary with 8226 field ID:category entries\n",
      "Parsed 1827 unique field IDs from the UKBiobank html file\n",
      "Time elapsed for extracting unique field IDs: 3.28003010712564\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mo/Env_vars_DL/UKBB.py:180: UserWarning: Some of the fieldIDs were not not found in self._UID_to_descrpt dictionary. Therefore their categories are not included in self.categories. See self.fieldID_no_category             for a list of these\n",
      "  warnings.warn(\"Some of the fieldIDs were not not found in self._UID_to_descrpt dictionary. Therefore their categories are not included in self.categories. See self.fieldID_no_category             for a list of these\")\n"
     ]
    }
   ],
   "source": [
    "ukb=UKBDicts(PATH_data,PATH_dict,\"file\")\n",
    "\n",
    "categories,UID_to_dscrpt,fieldID_to_ctgry_dict=ukb.categories,ukb._UID_to_dscrpt,ukb._fieldID_to_ctgry_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tic = time.perf_counter()\n",
    "column_names = pd.read_csv(PATH_data, dtype='unicode',nrows=1).columns\n",
    "df = pd.read_csv(PATH_data,dtype='unicode',engine='python')\n",
    "#df=next(df)\n",
    "toc = time.perf_counter()\n",
    "print('Time to read the data: '+str(toc-tic))\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3 Extract outcomes\n",
    "\n",
    "## 3.1 41270 & 41280 (primary and secondary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "outcomes=['I20-I25 Ischaemic heart diseases',\n",
    "'I30-I52 Other forms of heart disease',\n",
    "'I70-I79 Diseases of arteries, arterioles and capillaries'\n",
    "'I20.0 Unstable angina',\n",
    "'I20.9 Angina pectoris, unspecified',\n",
    "'I21 Acute myocardial infarction',\n",
    "'I25.1 Atherosclerotic heart disease',\n",
    "'I48 Atrial fibrillation and flutter', \n",
    "'I50 Heart failure']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# section below needs to be updated when the issue with pandas bool indexing has been resolved\n",
    "## I think this can be solved by converting the whole dataframe to datatime. at the moment some are datatime and some np.nan, converting all to datetime will convert Nan to NaT and then the conditional indexing can happen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "From the category Summary Diagnoses the following where selected: \n",
      " \t {'41270'}\n",
      "\t FID 41270:  Diagnoses - ICD10Uses data-coding 259\n",
      "From the category Summary Diagnoses the following where selected: \n",
      " \t {'41280'}\n",
      "\t FID 41280:  Date of first in-patient diagnosis - ICD10\n",
      "From the category Reception the following where selected: \n",
      " \t {'53'}\n",
      "\t FID 53:  Date of attending assessment centre\n"
     ]
    }
   ],
   "source": [
    "selected_categories={'Summary Diagnoses':['include','41270']}\n",
    "process_config={'41270':{'type':'string'}}\n",
    "\n",
    "df_temp=preprocess(selected_categories,ukb.categories,ukb._UID_to_dscrpt,df,process_config)\n",
    "\n",
    "\n",
    "selected_categories={'Summary Diagnoses':['include','41280']}\n",
    "process_config={'41280':{'type':'string'}}\n",
    "df_temp_date=preprocess(selected_categories,ukb.categories,ukb._UID_to_dscrpt,df,process_config)\n",
    "\n",
    "selected_categories1={fieldID_to_ctgry_dict['53'][1]:['include','53']}\n",
    "process_config1={'53':{'type':'string'}}\n",
    "\n",
    "df_date_assessment=pd.to_datetime(preprocess(selected_categories1,ukb.categories,\n",
    "                                             ukb._UID_to_dscrpt,df,process_config1)['53-0.0'],format='%Y-%m-%d').to_frame()\n",
    "\n",
    "#Outcomes\n",
    "I20_25= ['I'+str(i) for i in range(20,26)]\n",
    "I30_52=['I'+str(i) for i in range(30,53)]\n",
    "#I70_79=['I'+str(i) for i in range(70,80)]\n",
    "#outcomes_list=I20_25+I30_52+I70_79\n",
    "outcomes_list=I20_25+I30_52+[\"G45\",\"I63\",\"I64\"]\n",
    "\n",
    "#find the bool_indx when one of the outcomes is found in df_temp\n",
    "cols_dict={df_temp.columns.values[i]:df_temp_date.columns.values[i] for i in range(df_temp.shape[1])}\n",
    "bool_indxs=df_temp.apply(lambda col: col.str.contains('|'.join(outcomes_list), na=False), axis=1)\n",
    "#the corresponding bool indxing df for the dates dataframe\n",
    "bool_indxs_date=bool_indxs.rename(columns=cols_dict)\n",
    "\n",
    "\n",
    "#df_temp_date=df_temp_date[bool_indxs_date].apply(pd.to_datetime)\n",
    "\"\"\"This line above used to work but due to an error in pandas it doesn't, revert pack when pandas error has been fixed\"\"\"\n",
    "df_temp_date_X=pd.DataFrame(columns=df_temp_date.columns, index=df_temp_date.index)\n",
    "for col in bool_indxs_date.columns:\n",
    "    if bool_indxs_date.loc[:,col].sum()!=0:\n",
    "        df_temp_date_X.loc[bool_indxs_date.loc[:,col],col]=df_temp_date.loc[bool_indxs_date.loc[:,col],col].apply(pd.to_datetime)\n",
    "    \n",
    "\n",
    "the_earliest_outcome_diagnosis=df_temp_date_X.apply(pd.to_datetime).min(axis=1)# the first occurance of the disease(any of the ones specified in outcomes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "newdf=pd.DataFrame(index=df_temp.index,columns=['outcome_months','Exclude_outcomes','outcomes'])\n",
    "newdf.loc[the_earliest_outcome_diagnosis<df_date_assessment['53-0.0'],'Exclude_outcomes']=1\n",
    "\n",
    "newdf.loc[the_earliest_outcome_diagnosis>=df_date_assessment['53-0.0'],'outcomes']=1\n",
    "\n",
    "newdf['outcome_months']=the_earliest_outcome_diagnosis.sub(df_date_assessment['53-0.0'])\n",
    "newdf['outcome_months']=newdf['outcome_months']/np.timedelta64(1, 'M')\n",
    "\n",
    "#replace MI_months nans with the duration of time between may 2017 and date of attending the assessment centre\n",
    "indx=newdf.index[newdf['outcome_months'].isna()]\n",
    "newdf.loc[indx,'outcome_months']=(datetime(2017,5,1)-df_date_assessment['53-0.0'])/np.timedelta64(1, 'M')\n",
    "newdf.fillna(0,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_outcome_categories_tidy={'CVDs':['outcomes','outcome_months']}\n",
    "selected_outcome_categories_tidy_columns={'outcomes':{\"col_name\":['outcome'],\"type\":\"binary\"},\n",
    "                                         'outcome_months':{\"col_name\":['outcome_months'],\"type\":\"int\"}}\n",
    "selected_outcome_categories_exclusions=[\"Exclude_outcomes\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 40000 40001 & 40002 (death registry) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Field ID: 1807 _ Father's age at deathUses data-coding 100435\n",
      "\n",
      "Field ID: 3526 _ Mother's age at deathUses data-coding 100360\n",
      "\n",
      "Field ID: 4501 _ Non-accidental death in close genetic familyUses data-coding 100259\n",
      "\n",
      "Field ID: 20437 _ Thoughts of death during worst depressionUses data-coding 505\n",
      "\n",
      "Field ID: 20530 _ Witnessed sudden violent deathUses data-coding 533\n",
      "\n",
      "Field ID: 40000 _ Date of death\n",
      "\n",
      "Field ID: 40001 _ Underlying (primary) cause of death: ICD10Uses data-coding 19\n",
      "\n",
      "Field ID: 40002 _ Contributory (secondary) causes of death: ICD10Uses data-coding 19\n",
      "\n",
      "Field ID: 40007 _ Age at death\n",
      "\n",
      "Field ID: 40010 _ Description of cause of death\n",
      "\n",
      "Field ID: 40018 _ Death record formatUses data-coding 261\n",
      "\n",
      "Field ID: 40020 _ Death record originUses data-coding 1970\n",
      "\n",
      "None\n",
      "['Contributory (secondary) causes of death: ICD10', 'Death register']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['40000: Date of death',\n",
       " '40001: Underlying (primary) cause of death: ICD10Uses data-coding 19',\n",
       " '40002: Contributory (secondary) causes of death: ICD10Uses data-coding 19',\n",
       " '40007: Age at death',\n",
       " '40010: Description of cause of death',\n",
       " '40018: Death record formatUses data-coding 261',\n",
       " '40020: Death record originUses data-coding 1970']"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word='death'\n",
    "print(ukb.search_description(word))\n",
    "print(fieldID_to_ctgry_dict['40002'])\n",
    "categories['Death register']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "From the category Death register the following where selected: \n",
      " \t {'40002', '40001'}\n",
      "\t FID 40002:  Contributory (secondary) causes of death: ICD10Uses data-coding 19\n",
      "\t FID 40001:  Underlying (primary) cause of death: ICD10Uses data-coding 19\n",
      "From the category Death register the following where selected: \n",
      " \t {'40000'}\n",
      "\t FID 40000:  Date of death\n"
     ]
    }
   ],
   "source": [
    "selected_categories={'Death register':['include','40001','40002']}\n",
    "process_config={'40001':{'type':'string'},'40002':{'type':'string'}}\n",
    "\n",
    "df_temp=preprocess(selected_categories,ukb.categories,ukb._UID_to_dscrpt,df,process_config)\n",
    "\n",
    "selected_categories={'Death register':['include','40000']}\n",
    "process_config={'40000':{'type':'string'}}\n",
    "df_date_death=preprocess(selected_categories,ukb.categories,ukb._UID_to_dscrpt,df,process_config)['40000-0.0'].apply(pd.to_datetime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "bool_indxs=df_temp.apply(lambda col: col.str.contains('|'.join(outcomes_list), na=False), axis=1)\n",
    "df_date_death_outcome=df_date_death[bool_indxs.any(axis=1)] #this is death due to outcomes of interest (CVDs defined above)\n",
    "#find indices (patients) in newdf where death has been to do the outcomes (df_date_death_outcome.index) but have not had previous diagnoses, \n",
    "#i.e. outcomes=0 and exclude_outcomes=0\n",
    "indxs_to_be_updated=(newdf.iloc[df_date_death_outcome.index]['Exclude_outcomes']==0) & \\\n",
    "(newdf.iloc[df_date_death_outcome.index]['outcomes']==0)\n",
    "\n",
    "indxs_to_be_updated=indxs_to_be_updated[indxs_to_be_updated] #This contains only the true values (those that need to be updated)\n",
    "\n",
    "\n",
    "#now update the outcomes, and outcome_months of these indices\n",
    "newdf.loc[indxs_to_be_updated.index]['outcomes']=1\n",
    "newdf.loc[indxs_to_be_updated.index]['outcome_months']=df_date_death_outcome.loc[indxs_to_be_updated.index].sub(df_date_assessment.loc[indxs_to_be_updated.index,'53-0.0'])/np.timedelta64(1, 'M')\n",
    "\n",
    "newdf['death']=df_date_death\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Field ID: 190 _ Reason lost to follow-upUses data-coding 1965\n",
      "\n",
      "Field ID: 191 _ Date lost to follow-up\n",
      "\n",
      "Field ID: 20086 _ Type of special diet followedUses data-coding 76\n",
      "\n",
      "Field ID: 20554 _ Actions taken following self-harmUses data-coding 1423\n",
      "\n",
      "None\n",
      "['Contributory (secondary) causes of death: ICD10', 'Death register']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['40000: Date of death',\n",
       " '40001: Underlying (primary) cause of death: ICD10Uses data-coding 19',\n",
       " '40002: Contributory (secondary) causes of death: ICD10Uses data-coding 19',\n",
       " '40007: Age at death',\n",
       " '40010: Description of cause of death',\n",
       " '40018: Death record formatUses data-coding 261',\n",
       " '40020: Death record originUses data-coding 1970']"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word='follow'\n",
    "print(ukb.search_description(word))\n",
    "print(fieldID_to_ctgry_dict['40002'])\n",
    "categories['Death register']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Other Exclusions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Statin use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'(Int64Index([     4,     12,     18,     20,     31,     33,     34,     49,\n                50,     52,\n            ...\n            502482, 502483, 502488, 502490, 502499, 502504, 502510, 502516,\n            502519, 502526],\n           dtype='int64', length=78033), 'Exclude_statin_use')' is an invalid key",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-60-984905a73b0b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mtemp_bool_array\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcol\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mcol\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;34m'20003-0'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcol\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mstatin_codes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mindxs_temp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtemp_bool_array\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcol\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mcol\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;34m'20003-0'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcol\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mnewdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindxs_temp\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'Exclude_statin_use'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mselected_outcome_categories_exclusions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Exclude_statin_use'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2798\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2799\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2800\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2801\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2802\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2644\u001b[0m                 )\n\u001b[1;32m   2645\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2646\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2647\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2648\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_cast_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: '(Int64Index([     4,     12,     18,     20,     31,     33,     34,     49,\n                50,     52,\n            ...\n            502482, 502483, 502488, 502490, 502499, 502504, 502510, 502516,\n            502519, 502526],\n           dtype='int64', length=78033), 'Exclude_statin_use')' is an invalid key"
     ]
    }
   ],
   "source": [
    "newdf['Exclude_statin_use']=0\n",
    "statin_codes=['1140861958','1141146234','1140888594','1140888648','1141192410'] #simvastatin atorvastatin fluvastatin pravastatin rosuvastatin\n",
    "temp_bool_array=np.isin(df[[col for col in df.columns if '20003-0' in col]],statin_codes).any(axis=1)\n",
    "indxs_temp=df.loc[temp_bool_array,[col for col in df.columns if '20003-0' in col]].index\n",
    "newdf.loc[indxs_temp,'Exclude_statin_use']=1\n",
    "\n",
    "\n",
    "selected_outcome_categories_exclusions.append('Exclude_statin_use')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "newdf.to_csv(r'/home/mo/Env_vars_DL/tidy_data_tiles/Outcomes.csv')\n",
    "\n",
    "save_obj(selected_outcome_categories_tidy,'selected_outcome_categories_tidy')\n",
    "save_obj(selected_outcome_categories_tidy_columns,'selected_outcome_categories_tidy_columns')\n",
    "save_obj(selected_outcome_categories_exclusions,'selected_outcome_categories_exclusions')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
